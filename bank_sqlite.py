# -*- coding: utf-8 -*-
"""Bank_sqlite.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1httdGiKolvMxtvCMe3ELRvDEBJGrtT0C
"""

import pandas as pd

df = pd.read_csv("/content/bank_transactions.csv")
df.head()

import sqlite3

conn = sqlite3.connect("bank.db")
df.to_sql("bank_transactions", conn, index=False, if_exists="replace")

"""**Query for missing values**"""

conn = sqlite3.connect("bank.db")
query = """
SELECT
    COUNT(*) AS total_rows,
    SUM(CASE WHEN TransactionID IS NULL THEN 1 ELSE 0 END) AS missing_TransactionID,
    SUM(CASE WHEN CustomerID IS NULL THEN 1 ELSE 0 END) AS missing_CustomerID,
    SUM(CASE WHEN CustomerDOB IS NULL THEN 1 ELSE 0 END) AS missing_CustomerDOB,
    SUM(CASE WHEN CustGender IS NULL THEN 1 ELSE 0 END) AS missing_CustGender,
    SUM(CASE WHEN CustLocation IS NULL THEN 1 ELSE 0 END) AS missing_CustLocation,
    SUM(CASE WHEN CustAccountBalance IS NULL THEN 1 ELSE 0 END) AS missing_CustAccountBalance,
    SUM(CASE WHEN TransactionDate IS NULL THEN 1 ELSE 0 END) AS missing_TransactionDate,
    SUM(CASE WHEN TransactionTime IS NULL THEN 1 ELSE 0 END) AS missing_TransactionTime,
    SUM(CASE WHEN [TransactionAmount (INR)] IS NULL THEN 1 ELSE 0 END) AS missing_TransactionAmount
FROM bank_transactions;
"""

# Run SQL query and display missing values
missing_values = pd.read_sql(query, conn)
print(missing_values)

"""**Query for rows with missing values**"""

query = """
SELECT * FROM bank_transactions
WHERE TransactionID IS NULL
   OR CustomerID IS NULL
   OR CustomerDOB IS NULL
   OR CustGender IS NULL
   OR CustLocation IS NULL
   OR CustAccountBalance IS NULL
   OR TransactionDate IS NULL
   OR TransactionTime IS NULL
   OR [TransactionAmount (INR)] IS NULL;
"""
df_missing = pd.read_sql(query, conn)
df_missing.head()

"""**Query for count of total transactions**"""

query = "SELECT COUNT(*) AS total_transactions FROM bank_transactions;"
df_count = pd.read_sql(query, conn)
df_count

"""**Query for earliest and latest transactions**"""

query = """
SELECT
    MIN(TransactionDate) AS first_transaction,
    MAX(TransactionDate) AS last_transaction
FROM bank_transactions;
"""
df_dates = pd.read_sql(query, conn)
df_dates

"""**Query for customer counts (unique)**"""

query = """
SELECT COUNT(DISTINCT CustomerID)
AS unique_customers
FROM bank_transactions;"""
df_customers = pd.read_sql(query, conn)
df_customers

"""**Query for top 5 customer with the highest transactional amount**"""

query = """
SELECT CustomerID, SUM([TransactionAmount (INR)]) AS total_spent
FROM bank_transactions
GROUP BY CustomerID
ORDER BY total_spent DESC
LIMIT 5;
"""
df_top_customers = pd.read_sql(query, conn)
df_top_customers

"""**Query for average customer's account balance by location**"""

query = """
SELECT CustLocation, AVG(CustAccountBalance) AS avg_balance
FROM bank_transactions
GROUP BY CustLocation
ORDER BY avg_balance DESC;
"""
df_avg_balance = pd.read_sql(query, conn)
pd.options.display.float_format = '{:,.2f}'.format
print(df_avg_balance.head())

excel_filename = "bank_queries_output.xlsx"
with pd.ExcelWriter(excel_filename, mode="w", engine="openpyxl") as writer:
    df_avg_balance.to_excel(writer, sheet_name="Avg_Balance_by_Location", index=False)

print(f"Data saved to {excel_filename} in sheet 'Avg_Balance_by_Location'")

"""**Query for customer's transaction over time**"""

from openpyxl import load_workbook

query = """
SELECT TransactionDate, COUNT(*) AS total_transactions
FROM bank_transactions
GROUP BY TransactionDate
ORDER BY TransactionDate ASC;
"""
df_time_series = pd.read_sql(query, conn)
print(df_time_series.head())

excel_filename = "bank_queries_output.xlsx"
with pd.ExcelWriter(excel_filename, mode="a", engine="openpyxl", if_sheet_exists="replace") as writer:
    df_time_series.to_excel(writer, sheet_name="Transaction_Trend", index=False)

print(f"New data saved to {excel_filename} in sheet 'Transaction_Trend'")

"""**Query for the most common transactional time (aka peak hours)**"""

query = """
SELECT TransactionTime, COUNT(*) AS transaction_count
FROM bank_transactions
GROUP BY TransactionTime
ORDER BY transaction_count DESC
LIMIT 10;
"""
df_time = pd.read_sql(query, conn)
print(df_time)

excel_filename = "bank_queries_output.xlsx"
with pd.ExcelWriter(excel_filename, mode="a", engine="openpyxl", if_sheet_exists="replace") as writer:
    df_time.to_excel(writer, sheet_name="Transaction_Peak", index=False)

print(f"New data saved to {excel_filename} in sheet 'Transaction_Peak'")

"""**Query by customer's account balance grouping**"""

query = """
SELECT
    CustomerID,
    CustAccountBalance,
    CASE
        WHEN CustAccountBalance < 5000 THEN 'Low Balance'
        WHEN CustAccountBalance BETWEEN 5000 AND 20000 THEN 'Medium Balance'
        ELSE 'High Balance'
    END AS balance_category
FROM bank_transactions;
"""
df_segments = pd.read_sql(query, conn)
print(df_segments.head())

excel_filename = "bank_queries_output.xlsx"
with pd.ExcelWriter(excel_filename, mode="a", engine="openpyxl", if_sheet_exists="replace") as writer:
    df_segments.to_excel(writer, sheet_name="Curr_Balance_Category", index=False)

print(f"New data saved to {excel_filename} in sheet 'Curr_Balance_Category'")

"""**Query by high value customers' transactions (useful for unusual transactions)**"""

query = """
SELECT * FROM bank_transactions
WHERE [TransactionAmount (INR)] > 100000;
"""
df_large_transactions = pd.read_sql(query, conn)
print(df_large_transactions.head())

excel_filename = "bank_queries_output.xlsx"
with pd.ExcelWriter(excel_filename, mode="a", engine="openpyxl", if_sheet_exists="replace") as writer:
    df_large_transactions.to_excel(writer, sheet_name="High_Value_Transactions", index=False)

print(f"New data saved to {excel_filename} in sheet 'High_Value_Transactions'")

"""**Query for customers with over 3 transactions a day (useful for spotting suspicious activity)**"""

query = """
SELECT CustomerID, TransactionDate, COUNT(*) AS num_transactions
FROM bank_transactions
GROUP BY CustomerID, TransactionDate
HAVING num_transactions > 3;
"""
df_frequent = pd.read_sql(query, conn)
df_frequent